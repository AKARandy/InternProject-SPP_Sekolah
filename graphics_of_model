{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":13181105,"sourceType":"datasetVersion","datasetId":8353043},{"sourceId":13195252,"sourceType":"datasetVersion","datasetId":8362167},{"sourceId":13298188,"sourceType":"datasetVersion","datasetId":8428640},{"sourceId":13381960,"sourceType":"datasetVersion","datasetId":8490615}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# ================== Learning Curve + dll ==================\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom datetime import datetime\nimport joblib, warnings, os, json, time\nfrom sklearn.model_selection import KFold, learning_curve, cross_val_predict\nfrom sklearn.metrics import make_scorer, r2_score, mean_absolute_error, mean_absolute_percentage_error\nfrom catboost import CatBoostRegressor\nwarnings.filterwarnings(\"ignore\")\n\n# --------- CONFIG: update these 3 paths to your saved files ----------\nDATA_PATH = \"/kaggle/input/ashw-tdi-salah/Gabungan_Surabaya_Sidoarjo.csv\"\nBEST_MODEL_PATH = \"/kaggle/input/fixed-10-fold-no-filter/top_models_by_MAE_20251008_134550/rank_1_MAE_688901.55_std_291912.05.pkl\"   # <- ganti filenya sesuai hasil cv\nFEATURES_META_PATH = \"/kaggle/input/fixed-10-fold-no-filter/model_features_20251008_134550.pkl\"  # <- ganti filenya sesuai hasil cv\n# ---------------------------------------------------------------------\n\n# === Load saved model\n_loaded = joblib.load(BEST_MODEL_PATH)\nmodel_saved = _loaded[\"model\"] if isinstance(_loaded, dict) and \"model\" in _loaded else _loaded\n\n# === Load feature metadata (features + categorical_features)\nmeta = joblib.load(FEATURES_META_PATH)\nfeatures = meta[\"features\"]\ncategorical_features = meta[\"categorical_features\"]\n\ndf = pd.read_csv(DATA_PATH)\n\n# Clean SPP\ndf[\"SPP\"] = pd.to_numeric(df[\"SPP\"], errors=\"coerce\").fillna(0).astype(int)\ndf = df[df[\"SPP\"] > 0]\n#df = df[df[\"Peserta Didik\"] >= 100]\n\n# Whitelist\ndf.loc[df[\"Yayasan\"] == \"YAYASAN PEMBINA UNIVERSITAS NEGERI JAKARTA\", \"Kurikulum\"] = \"Kurikulum Internasional\"\n\n# Drop cols\ndf = df.drop(columns=[\"Yayasan\", \"Website\", \"NPSN\"], errors=\"ignore\")\n\n# Fill missing numeric cols with mean (excluding zeros)\nto_fill = [\"meter listrik\",\"harga_listrik_per_bulan\",\"estimasi harga tanah sekolah\",\n           \"Tanggal SK Pendirian\",\"Umur\",\"luas tanah\"]\nfor col in to_fill:\n    df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n    mean_value = df[df[col] != 0][col].mean()\n    df[col] = df[col].replace(0, mean_value).fillna(mean_value)\n\n# Feature engineering (same)\ndf[\"rombel_luas_ratio\"] = df[\"Rombel\"] / df[\"luas tanah\"]\ndf[\"total_rooms\"] = df[\"R.Kelas\"] + df[\"R.Lab\"] + df[\"R.Perpus\"]\ndf[\"total_rooms_luas_ratio\"] = df[\"total_rooms\"] / df[\"luas tanah\"]\ndf[\"total_rooms_listrik_ratio\"] = df[\"total_rooms\"] / df[\"meter listrik\"]\ndf[\"listrik_cost_rooms_ratio\"] = df[\"harga_listrik_per_bulan\"] / df[\"total_rooms\"]\n\n# Replace inf/NaN with medians\ndf = df.replace([np.inf, -np.inf], np.nan)\nfor col in df.select_dtypes(include=[np.number]).columns:\n    df[col] = df[col].fillna(df[col].median())\n\n# Targets (same)\ndf[\"Buying Power\"] = df[\"SPP\"] * df[\"Peserta Didik\"]\ndf[\"Buying Power_log\"] = np.log1p(df[\"Buying Power\"])\ndf[\"SPP_log\"] = np.log1p(df[\"SPP\"])\n\ntarget = \"SPP_log\"\nexclude = [\"SPP\",\"SPP_log\",\"Buying Power\",\"Buying Power_log\",\"Nama_sekolah\"]\nX = df[[c for c in df.columns if c not in exclude]].copy()\ny = df[target].copy()\n\n# Ensure categorical columns are str (CatBoost by name)\nfor c in categorical_features:\n    if c in X.columns:\n        X[c] = X[c].astype(str)\n\nprint(f\"Prepared data: X={X.shape}, y={y.shape}\")\n\n# === Custom scorers (original-scale)\ndef r2_original_scorer(y_true, y_pred):\n    return r2_score(np.expm1(y_true), np.expm1(y_pred))\n\ndef r2_log_scorer(y_true, y_pred):\n    return r2_score(y_true, y_pred)\n\ndef mae_original_scorer(y_true, y_pred):\n    y_true_orig, y_pred_orig = np.expm1(y_true), np.expm1(y_pred)\n    return -mean_absolute_error(y_true_orig, y_pred_orig)  # neg for \"higher-is-better\"\n\ndef mape_original_scorer(y_true, y_pred):\n    y_true_orig, y_pred_orig = np.expm1(y_true), np.expm1(y_pred)\n    return -mean_absolute_percentage_error(y_true_orig, y_pred_orig)  # neg for \"higher-is-better\"\n\n# === K-Fold (same seed/shuffle as training)\ncv = KFold(n_splits=10, shuffle=True, random_state=42)\n\n# === Build an unfitted clone with same hyperparams as the saved model\nbest_params = model_saved.get_params(deep=False)\nbest_params.update(dict(cat_features=categorical_features, verbose=False, task_type=best_params.get(\"task_type\",\"GPU\")))\nlc_model = CatBoostRegressor(**best_params)\n\n# In CV, the max effective train fraction per fold is (K-1)/K\nmax_frac = (cv.n_splits - 1) / cv.n_splits\ntrain_sizes = np.linspace(0.1, max_frac, 12)\n\n# ========== 1. GET PREDICTIONS FOR SCATTER PLOTS ==========\nprint(\"\\nGenerating cross-validated predictions...\")\ny_pred_log = cross_val_predict(lc_model, X, y, cv=cv, n_jobs=1)\ny_pred_original = np.expm1(y_pred_log)\ny_true_original = np.expm1(y)\n\n# Calculate metrics\nr2_orig = r2_score(y_true_original, y_pred_original)\nmae_orig = mean_absolute_error(y_true_original, y_pred_original)\nmape_orig = mean_absolute_percentage_error(y_true_original, y_pred_original)\n\nprint(f\"CV Metrics - R²: {r2_orig:.4f}, MAE: {mae_orig:.2f}, MAPE: {mape_orig:.4f}\")\n\n# ========== 2. PREDICTED VS ACTUAL (REAL SCALE) ==========\nplt.figure(figsize=(8,8))\nplt.scatter(y_true_original, y_pred_original, alpha=0.5, s=20)\nmin_val = min(y_true_original.min(), y_pred_original.min())\nmax_val = max(y_true_original.max(), y_pred_original.max())\nplt.plot([min_val, max_val], [min_val, max_val], 'r--', lw=2, label='Perfect prediction')\nplt.xlabel('Actual SPP (Original Scale)')\nplt.ylabel('Predicted SPP (Original Scale)')\nplt.title(f'Predicted vs Actual (Original Scale)\\nR² = {r2_orig:.4f}, MAE = {mae_orig:.2f}')\nplt.legend()\nplt.tight_layout()\nts = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\nout_png = f\"pred_vs_actual_original_{ts}.png\"\nplt.savefig(out_png, dpi=300, bbox_inches=\"tight\")\nplt.show()\nprint(f\"✓ Predicted vs Actual (original) saved to: {out_png}\")\n\n# ========== 3. PREDICTED VS ACTUAL (LOG SCALE) ==========\nplt.figure(figsize=(8,8))\nplt.scatter(y, y_pred_log, alpha=0.5, s=20)\nmin_val = min(y.min(), y_pred_log.min())\nmax_val = max(y.max(), y_pred_log.max())\nplt.plot([min_val, max_val], [min_val, max_val], 'r--', lw=2, label='Perfect prediction')\nplt.xlabel('Actual SPP (Log Scale)')\nplt.ylabel('Predicted SPP (Log Scale)')\nr2_log = r2_score(y, y_pred_log)\nplt.title(f'Predicted vs Actual (Log Scale)\\nR² = {r2_log:.4f}')\nplt.legend()\nplt.tight_layout()\nts = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\nout_png = f\"pred_vs_actual_log_{ts}.png\"\nplt.savefig(out_png, dpi=300, bbox_inches=\"tight\")\nplt.show()\nprint(f\"✓ Predicted vs Actual (log) saved to: {out_png}\")\n\n# ========== 4. RESIDUAL PLOT (ORIGINAL SCALE) ==========\nresiduals = y_true_original - y_pred_original\n\nplt.figure(figsize=(10,6))\nplt.scatter(y_pred_original, residuals, alpha=0.5, s=20)\nplt.axhline(y=0, color='r', linestyle='--', lw=2)\nplt.xlabel('Predicted SPP (Original Scale)')\nplt.ylabel('Residuals (Actual - Predicted)')\nplt.title('Residual Plot (Original Scale)')\nplt.tight_layout()\nts = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\nout_png = f\"residual_plot_original_{ts}.png\"\nplt.savefig(out_png, dpi=300, bbox_inches=\"tight\")\nplt.show()\nprint(f\"✓ Residual plot (original) saved to: {out_png}\")\n\n# ========== 5. RESIDUAL PLOT (LOG SCALE) ==========\nresiduals_log = y - y_pred_log\n\nplt.figure(figsize=(10,6))\nplt.scatter(y_pred_log, residuals_log, alpha=0.5, s=20)\nplt.axhline(y=0, color='r', linestyle='--', lw=2)\nplt.xlabel('Predicted SPP (Log Scale)')\nplt.ylabel('Residuals (Actual - Predicted)')\nplt.title('Residual Plot (Log Scale)')\nplt.tight_layout()\nts = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\nout_png = f\"residual_plot_log_{ts}.png\"\nplt.savefig(out_png, dpi=300, bbox_inches=\"tight\")\nplt.show()\nprint(f\"✓ Residual plot (log) saved to: {out_png}\")\n\n# ========== ORIGINAL LEARNING CURVES ==========\n\n# === Learning curve (R² original scale)\nprint(\"\\nGenerating learning curve (R² original scale)...\")\nts_abs, tr_scores, va_scores = learning_curve(\n    estimator=lc_model,\n    X=X, y=y,\n    cv=cv,\n    scoring=make_scorer(r2_original_scorer),\n    train_sizes=train_sizes,\n    n_jobs=1,\n    shuffle=False\n)\n\ntr_mean, tr_std = tr_scores.mean(axis=1), tr_scores.std(axis=1)\nva_mean, va_std = va_scores.mean(axis=1), va_scores.std(axis=1)\n\n# Plot\nplt.figure(figsize=(8,5))\nplt.title(\"Learning Curve (Saved CatBoost) — R² (original scale)\")\nplt.plot(ts_abs, tr_mean, linestyle=\"--\", label=\"Training score\")\nplt.plot(ts_abs, va_mean, label=\"Cross-validation score\")\nplt.fill_between(ts_abs, tr_mean-tr_std, tr_mean+tr_std, alpha=0.15)\nplt.fill_between(ts_abs, va_mean-va_std, va_mean+va_std, alpha=0.15)\nplt.xlabel(\"Training set size (samples)\")\nplt.ylabel(\"R² (original)\")\nplt.legend()\nplt.tight_layout()\nts = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\nout_png = f\"learning_curve_r2_original_{ts}.png\"\nplt.savefig(out_png, dpi=300, bbox_inches=\"tight\")\nplt.show()\nprint(f\"✓ Learning curve (R² original) saved to: {out_png}\")\n\n# === Learning curve (R² log scale) ===\nprint(\"\\nGenerating learning curve (R² log scale)...\")\nts_abs_log, tr_scores_log, va_scores_log = learning_curve(\n    estimator=lc_model,\n    X=X, y=y,\n    cv=cv,\n    scoring=make_scorer(r2_log_scorer),\n    train_sizes=train_sizes,\n    n_jobs=1,\n    shuffle=False\n)\n\ntr_mean_log = tr_scores_log.mean(axis=1)\ntr_std_log = tr_scores_log.std(axis=1)\nva_mean_log = va_scores_log.mean(axis=1)\nva_std_log = va_scores_log.std(axis=1)\n\n# Plot\nplt.figure(figsize=(8,5))\nplt.title(\"Learning Curve (Saved CatBoost) — R² (log scale)\")\nplt.plot(ts_abs_log, tr_mean_log, linestyle=\"--\", label=\"Training score\")\nplt.plot(ts_abs_log, va_mean_log, label=\"Cross-validation score\")\nplt.fill_between(ts_abs_log, tr_mean_log-tr_std_log, tr_mean_log+tr_std_log, alpha=0.15)\nplt.fill_between(ts_abs_log, va_mean_log-va_std_log, va_mean_log+va_std_log, alpha=0.15)\nplt.xlabel(\"Training set size (samples)\")\nplt.ylabel(\"R² (log)\")\nplt.legend()\nplt.tight_layout()\nts = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\nout_png = f\"learning_curve_r2_log_{ts}.png\"\nplt.savefig(out_png, dpi=300, bbox_inches=\"tight\")\nplt.show()\nprint(f\"✓ Learning curve (R² log) saved to: {out_png}\")\n\n# === Learning curve (MAE on original scale) ===\nprint(\"\\nGenerating learning curve (MAE)...\")\nts_abs_mae, tr_scores_mae, va_scores_mae = learning_curve(\n    estimator=lc_model,\n    X=X, y=y,\n    cv=cv,\n    scoring=make_scorer(mae_original_scorer),\n    train_sizes=train_sizes,\n    n_jobs=1,\n    shuffle=False\n)\n\n# Convert to POSITIVE MAE\ntr_mean_mae = (-tr_scores_mae).mean(axis=1)\ntr_std_mae  = tr_scores_mae.std(axis=1)\nva_mean_mae = (-va_scores_mae).mean(axis=1)\nva_std_mae  = va_scores_mae.std(axis=1)\n\n# Plot\nplt.figure(figsize=(8,5))\nplt.title(\"Learning Curve (Saved CatBoost) — MAE (original scale)\")\nplt.plot(ts_abs_mae, tr_mean_mae, linestyle=\"--\", label=\"Training MAE\")\nplt.plot(ts_abs_mae, va_mean_mae, label=\"CV MAE\")\nplt.fill_between(ts_abs_mae, tr_mean_mae-tr_std_mae, tr_mean_mae+tr_std_mae, alpha=0.15)\nplt.fill_between(ts_abs_mae, va_mean_mae-va_std_mae, va_mean_mae+va_std_mae, alpha=0.15)\nplt.xlabel(\"Training set size (samples)\")\nplt.ylabel(\"MAE (lower is better)\")\nplt.legend()\nplt.tight_layout()\nts_mae = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\nout_png_mae = f\"learning_curve_mae_original_{ts_mae}.png\"\nplt.savefig(out_png_mae, dpi=300, bbox_inches=\"tight\")\nplt.show()\nprint(f\"✓ Learning curve (MAE) saved to: {out_png_mae}\")\n\n# ========== 5. LEARNING CURVE (MAPE - ORIGINAL SCALE) ==========\nprint(\"\\nGenerating learning curve (MAPE)...\")\nts_abs_mape, tr_scores_mape, va_scores_mape = learning_curve(\n    estimator=lc_model,\n    X=X, y=y,\n    cv=cv,\n    scoring=make_scorer(mape_original_scorer),\n    train_sizes=train_sizes,\n    n_jobs=1,\n    shuffle=False\n)\n\n# Convert to POSITIVE MAPE (as percentage)\ntr_mean_mape = (-tr_scores_mape).mean(axis=1) * 100\ntr_std_mape  = tr_scores_mape.std(axis=1) * 100\nva_mean_mape = (-va_scores_mape).mean(axis=1) * 100\nva_std_mape  = va_scores_mape.std(axis=1) * 100\n\n# Plot\nplt.figure(figsize=(8,5))\nplt.title(\"Learning Curve (Saved CatBoost) — MAPE (original scale)\")\nplt.plot(ts_abs_mape, tr_mean_mape, linestyle=\"--\", label=\"Training MAPE\")\nplt.plot(ts_abs_mape, va_mean_mape, label=\"CV MAPE\")\nplt.fill_between(ts_abs_mape, tr_mean_mape-tr_std_mape, tr_mean_mape+tr_std_mape, alpha=0.15)\nplt.fill_between(ts_abs_mape, va_mean_mape-va_std_mape, va_mean_mape+va_std_mape, alpha=0.15)\nplt.xlabel(\"Training set size (samples)\")\nplt.ylabel(\"MAPE % (lower is better)\")\nplt.legend()\nplt.tight_layout()\nts_mape = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\nout_png_mape = f\"learning_curve_mape_original_{ts_mape}.png\"\nplt.savefig(out_png_mape, dpi=300, bbox_inches=\"tight\")\nplt.show()\nprint(f\"✓ Learning curve (MAPE) saved to: {out_png_mape}\")\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"ALL PLOTS GENERATED SUCCESSFULLY!\")\nprint(f\"Total plots created: 9\")\nprint(\"=\"*60)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-10-17T08:28:08.914447Z","iopub.execute_input":"2025-10-17T08:28:08.914784Z","iopub.status.idle":"2025-10-17T08:28:11.515889Z","shell.execute_reply.started":"2025-10-17T08:28:08.914753Z","shell.execute_reply":"2025-10-17T08:28:11.514094Z"}},"outputs":[{"name":"stdout","text":"Prepared data: X=(302, 27), y=(302,)\n\nGenerating cross-validated predictions...\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_36/253791242.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;31m# ========== 1. GET PREDICTIONS FOR SCATTER PLOTS ==========\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nGenerating cross-validated predictions...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m \u001b[0my_pred_log\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_val_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlc_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m \u001b[0my_pred_original\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpm1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred_log\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0my_true_original\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpm1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_val_predict\u001b[0;34m(estimator, X, y, groups, cv, n_jobs, verbose, fit_params, pre_dispatch, method)\u001b[0m\n\u001b[1;32m    984\u001b[0m     \u001b[0;31m# independent, and that it is pickle-able.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    985\u001b[0m     \u001b[0mparallel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mParallel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpre_dispatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpre_dispatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 986\u001b[0;31m     predictions = parallel(\n\u001b[0m\u001b[1;32m    987\u001b[0m         delayed(_fit_and_predict)(\n\u001b[1;32m    988\u001b[0m             \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mdelayed_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         )\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable_with_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1984\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_sequential_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1985\u001b[0m             \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1986\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_generator\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1987\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1988\u001b[0m         \u001b[0;31m# Let's create an ID that uniquely identifies the current call. If the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1912\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_dispatched_batches\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1913\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_dispatched_tasks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1914\u001b[0;31m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1915\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_completed_tasks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1916\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_progress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_predict\u001b[0;34m(estimator, X, y, train, test, verbose, fit_params, method)\u001b[0m\n\u001b[1;32m   1066\u001b[0m         \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1067\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1068\u001b[0;31m         \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1069\u001b[0m     \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1070\u001b[0m     \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/catboost/core.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, cat_features, text_features, embedding_features, graph, sample_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[0m\n\u001b[1;32m   5871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'loss_function'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5872\u001b[0m             \u001b[0mCatBoostRegressor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_is_compatible_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss_function'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5873\u001b[0;31m         return self._fit(X, y, cat_features, text_features, embedding_features, None, graph, sample_weight, None, None, None, None, baseline,\n\u001b[0m\u001b[1;32m   5874\u001b[0m                          \u001b[0muse_best_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogging_level\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplot_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumn_description\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5875\u001b[0m                          \u001b[0mverbose_eval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric_period\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msilent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/catboost/core.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, cat_features, text_features, embedding_features, pairs, graph, sample_weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[0m\n\u001b[1;32m   2408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2409\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mplot_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplot_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Training plots'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_get_train_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2410\u001b[0;31m                 self._train(\n\u001b[0m\u001b[1;32m   2411\u001b[0m                     \u001b[0mtrain_pool\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2412\u001b[0m                     \u001b[0mtrain_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"eval_sets\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/catboost/core.py\u001b[0m in \u001b[0;36m_train\u001b[0;34m(self, train_pool, test_pool, params, allow_clear_pool, init_model)\u001b[0m\n\u001b[1;32m   1788\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1789\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_clear_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1790\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_object\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_clear_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_object\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0minit_model\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1791\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_trained_model_attributes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1792\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost._CatBoost._train\u001b[0;34m()\u001b[0m\n","\u001b[0;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost._CatBoost._train\u001b[0;34m()\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":1},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}
